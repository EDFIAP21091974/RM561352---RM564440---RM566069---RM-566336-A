{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EDFIAP21091974/RM561352---RM564440---RM566069---RM-566336-A/blob/main/Tarefa1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "73351f30-4b48-4c22-bd01-2069a91c4ebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73351f30-4b48-4c22-bd01-2069a91c4ebe",
        "outputId": "59913f72-b087-493d-a324-d79aa2b0a5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17611, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 17611 (delta 8), reused 2 (delta 2), pack-reused 17595 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17611/17611), 16.89 MiB | 20.54 MiB/s, done.\n",
            "Resolving deltas: 100% (11987/11987), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.2)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.64 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.3.217-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.64->-r requirements.txt (line 18))\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.217-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.217 ultralytics-thop-2.0.17\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Clonar o repositório YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "\n",
        "# Instalar dependências necessárias\n",
        "!pip install -r requirements.txt\n",
        "!pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a0be8599-2582-4bc9-8e81-7418f86739db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0be8599-2582-4bc9-8e81-7418f86739db",
        "outputId": "08635278-67a1-4d21-c784-351cb90a1e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir caminhos base\n",
        "BASE_PATH = '/content/drive/MyDrive/FarmTech_YOLO_Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1257d2be-e46f-477e-bac8-14b20a240625",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1257d2be-e46f-477e-bac8-14b20a240625",
        "outputId": "e6ae7a8d-9f67-4eb7-d398-3b80328e4a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Verificar se há GPU disponível\n",
        "!nvidia-smi\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "165875fe-fb08-464b-8331-f5151f718b7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165875fe-fb08-464b-8331-f5151f718b7b",
        "outputId": "7af18190-ece0-4e51-eb91-b71af08c55c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/images/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/images/train/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/images/val/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/images/test/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/labels/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/labels/train/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/labels/val/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/labels/test/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/models/\n",
            "✅ Pasta criada/verificada: /content/drive/MyDrive/FarmTech_YOLO_Project/results/\n"
          ]
        }
      ],
      "source": [
        "# Criar estrutura de pastas no Google Drive\n",
        "import os\n",
        "\n",
        "def criar_estrutura_pastas():\n",
        "    pastas = [\n",
        "        f'{BASE_PATH}',\n",
        "        f'{BASE_PATH}dataset/',\n",
        "        f'{BASE_PATH}dataset/images/',\n",
        "        f'{BASE_PATH}dataset/images/train/',\n",
        "        f'{BASE_PATH}dataset/images/val/',\n",
        "        f'{BASE_PATH}dataset/images/test/',\n",
        "        f'{BASE_PATH}dataset/labels/',\n",
        "        f'{BASE_PATH}dataset/labels/train/',\n",
        "        f'{BASE_PATH}dataset/labels/val/',\n",
        "        f'{BASE_PATH}dataset/labels/test/',\n",
        "        f'{BASE_PATH}models/',\n",
        "        f'{BASE_PATH}results/'\n",
        "    ]\n",
        "\n",
        "    for pasta in pastas:\n",
        "        os.makedirs(pasta, exist_ok=True)\n",
        "        print(f\"✅ Pasta criada/verificada: {pasta}\")\n",
        "\n",
        "criar_estrutura_pastas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6de32cf8-c93b-4796-8601-658e5942de87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6de32cf8-c93b-4796-8601-658e5942de87",
        "outputId": "35c758e6-42ae-4535-c2ba-67e02dd27320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Contagem de Imagens no Dataset:\n",
            "--------------------------------------------------\n",
            "TRAIN    |   0 imagens\n",
            "VAL      |   0 imagens\n",
            "TEST     |   0 imagens\n",
            "--------------------------------------------------\n",
            "TOTAL    |   0 imagens\n",
            "\n",
            "⚠️ ATENÇÃO: Você precisa adicionar as imagens nas pastas correspondentes!\n",
            "Distribuição esperada:\n",
            "- Train: 64 imagens (32 cachorros + 32 gatos)\n",
            "- Val: 8 imagens (4 cachorros + 4 gatos)\n",
            "- Test: 8 imagens (4 cachorros + 4 gatos)\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "def contar_imagens():\n",
        "    \"\"\"\n",
        "    Conta o número de imagens em cada pasta\n",
        "    \"\"\"\n",
        "    print(\"📊 Contagem de Imagens no Dataset:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    pastas = ['train', 'val', 'test']\n",
        "    total_geral = 0\n",
        "\n",
        "    for pasta in pastas:\n",
        "        caminho = f'{BASE_PATH}dataset/images/{pasta}/'\n",
        "        imagens = glob.glob(f'{caminho}*.jpg') + glob.glob(f'{caminho}*.png')\n",
        "        total = len(imagens)\n",
        "        total_geral += total\n",
        "\n",
        "        print(f\"{pasta.upper():8} | {total:3} imagens\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TOTAL    | {total_geral:3} imagens\")\n",
        "\n",
        "    return total_geral\n",
        "\n",
        "# Executar contagem\n",
        "total = contar_imagens()\n",
        "\n",
        "if total < 80:\n",
        "    print(\"\\n⚠️ ATENÇÃO: Você precisa adicionar as imagens nas pastas correspondentes!\")\n",
        "    print(\"Distribuição esperada:\")\n",
        "    print(\"- Train: 64 imagens (32 cachorros + 32 gatos)\")\n",
        "    print(\"- Val: 8 imagens (4 cachorros + 4 gatos)\")\n",
        "    print(\"- Test: 8 imagens (4 cachorros + 4 gatos)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6c057dae-0bc5-481d-8d69-bf347d0f2212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c057dae-0bc5-481d-8d69-bf347d0f2212",
        "outputId": "9f5f4b52-1bec-44f6-a6e1-06a1487177f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Arquivo de configuração criado!\n",
            "📍 Localização: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset.yaml\n",
            "\n",
            "📄 Conteúdo:\n",
            "\n",
            "# Dataset de Cachorros e Gatos - FarmTech Solutions\n",
            "path: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/  # caminho para o dataset\n",
            "train: images/train/  # imagens de treino\n",
            "val: images/val/      # imagens de validação\n",
            "test: images/test/    # imagens de teste\n",
            "\n",
            "# Classes\n",
            "nc: 2  # número de classes\n",
            "names: ['cachorro', 'gato']  # nomes das classes\n",
            "\n",
            "# Informações do projeto\n",
            "project: 'FarmTech_Animal_Detection'\n",
            "author: 'FarmTech Solutions Team'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Criar arquivo de configuração do dataset\n",
        "yaml_content = f\"\"\"\n",
        "# Dataset de Cachorros e Gatos - FarmTech Solutions\n",
        "path: {BASE_PATH}dataset/  # caminho para o dataset\n",
        "train: images/train/  # imagens de treino\n",
        "val: images/val/      # imagens de validação\n",
        "test: images/test/    # imagens de teste\n",
        "\n",
        "# Classes\n",
        "nc: 2  # número de classes\n",
        "names: ['cachorro', 'gato']  # nomes das classes\n",
        "\n",
        "# Informações do projeto\n",
        "project: 'FarmTech_Animal_Detection'\n",
        "author: 'FarmTech Solutions Team'\n",
        "\"\"\"\n",
        "\n",
        "# Salvar arquivo YAML\n",
        "yaml_path = f'{BASE_PATH}dataset.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"✅ Arquivo de configuração criado!\")\n",
        "print(f\"📍 Localização: {yaml_path}\")\n",
        "print(\"\\n📄 Conteúdo:\")\n",
        "print(yaml_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2b6ee86a-dc8a-4bdc-bb1e-1e7cd339bc6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b6ee86a-dc8a-4bdc-bb1e-1e7cd339bc6d",
        "outputId": "55b594c0-bf81-45c1-8b5a-e80faecb4347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ INICIANDO TREINAMENTO - SIMULAÇÃO 1 (30 épocas)\n",
            "============================================================\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-10-17 16:03:28.643221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760717008.667801     887 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760717008.674812     887 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760717008.694483     887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760717008.694534     887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760717008.694539     887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760717008.694543     887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/FarmTech_YOLO_Project/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/FarmTech_YOLO_Project/results, name=simulacao_30_epocas, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-441-g15c0127a Python-3.12.12 torch-2.8.0+cu126 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/FarmTech_YOLO_Project/results', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 14.4MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 116MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 590, in __init__\n",
            "    assert self.im_files, f\"{prefix}No images found\"\n",
            "           ^^^^^^^^^^^^^\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 988, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 690, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 287, in train\n",
            "    train_loader, dataset = create_dataloader(\n",
            "                            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 184, in create_dataloader\n",
            "    dataset = LoadImagesAndLabels(\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 592, in __init__\n",
            "    raise Exception(f\"{prefix}Error loading data from {path}: {e}\\n{HELP_URL}\") from e\n",
            "Exception: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/images/train: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found\n",
            "See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n",
            "\n",
            "✅ Treinamento da Simulação 1 concluído!\n"
          ]
        }
      ],
      "source": [
        "print(\"🏋️ INICIANDO TREINAMENTO - SIMULAÇÃO 1 (30 épocas)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Treinar modelo com 30 épocas\n",
        "!python train.py \\\n",
        "    --img 640 \\\n",
        "    --batch 16 \\\n",
        "    --epochs 30 \\\n",
        "    --data {yaml_path} \\\n",
        "    --weights yolov5s.pt \\\n",
        "    --cache \\\n",
        "    --project {BASE_PATH}results \\\n",
        "    --name simulacao_30_epocas \\\n",
        "    --exist-ok\n",
        "\n",
        "print(\"\\n✅ Treinamento da Simulação 1 concluído!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🏋️ INICIANDO TREINAMENTO - SIMULAÇÃO 2 (60 épocas)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Treinar modelo com 60 épocas\n",
        "!python train.py \\\n",
        "    --img 640 \\\n",
        "    --batch 16 \\\n",
        "    --epochs 60 \\\n",
        "    --data {yaml_path} \\\n",
        "    --weights yolov5s.pt \\\n",
        "    --cache \\\n",
        "    --project {BASE_PATH}results \\\n",
        "    --name simulacao_60_epocas \\\n",
        "    --exist-ok\n",
        "\n",
        "print(\"\\n✅ Treinamento da Simulação 2 concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvDXWUK8AIZq",
        "outputId": "a0cb34de-68c5-45a4-f07e-6cb8d2d4ddba"
      },
      "id": "ZvDXWUK8AIZq",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏋️ INICIANDO TREINAMENTO - SIMULAÇÃO 2 (60 épocas)\n",
            "============================================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-10-17 16:04:19.589445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760717059.616027    1370 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760717059.624085    1370 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760717059.642845    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760717059.642899    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760717059.642904    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760717059.642911    1370 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/drive/MyDrive/FarmTech_YOLO_Project/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/FarmTech_YOLO_Project/results, name=simulacao_60_epocas, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-441-g15c0127a Python-3.12.12 torch-2.8.0+cu126 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/FarmTech_YOLO_Project/results', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 590, in __init__\n",
            "    assert self.im_files, f\"{prefix}No images found\"\n",
            "           ^^^^^^^^^^^^^\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 988, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 690, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 287, in train\n",
            "    train_loader, dataset = create_dataloader(\n",
            "                            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 184, in create_dataloader\n",
            "    dataset = LoadImagesAndLabels(\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 592, in __init__\n",
            "    raise Exception(f\"{prefix}Error loading data from {path}: {e}\\n{HELP_URL}\") from e\n",
            "Exception: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/drive/MyDrive/FarmTech_YOLO_Project/dataset/images/train: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found\n",
            "See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\n",
            "\n",
            "✅ Treinamento da Simulação 2 concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def visualizar_resultados(nome_experimento):\n",
        "    \"\"\"\n",
        "    Visualiza os resultados do treinamento\n",
        "    \"\"\"\n",
        "    results_path = os.path.join(BASE_PATH, 'results', nome_experimento)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"📊 RESULTADOS - {nome_experimento}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Mostrar imagem de resultados\n",
        "    results_png = os.path.join(results_path, 'results.png')\n",
        "    if os.path.exists(results_png):\n",
        "        print(\"\\n📈 Gráficos de treinamento:\")\n",
        "        display(Image(filename=str(results_png)))\n",
        "    else:\n",
        "        print(f\"⚠️  Arquivo de resultados não encontrado: {results_png}\")\n",
        "\n",
        "    # Mostrar matriz de confusão\n",
        "    confusion_matrix = os.path.join(results_path, 'confusion_matrix.png')\n",
        "    if os.path.exists(confusion_matrix):\n",
        "        print(\"\\n🔲 Matriz de Confusão:\")\n",
        "        display(Image(filename=str(confusion_matrix)))\n",
        "\n",
        "    # Leer CSV de resultados\n",
        "    results_csv = os.path.join(results_path, 'results.csv')\n",
        "    if os.path.exists(results_csv):\n",
        "        df = pd.read_csv(results_csv)\n",
        "        df.columns = [col.strip() for col in df.columns]\n",
        "\n",
        "        print(\"\\n📊 Métricas finais (últimas 5 épocas):\")\n",
        "        cols_to_show = ['epoch', 'train/box_loss', 'val/box_loss',\n",
        "                        'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5']\n",
        "\n",
        "        # Verificar quais colunas existem\n",
        "        existing_cols = [col for col in cols_to_show if col in df.columns]\n",
        "        print(df[existing_cols].tail())\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"⚠️  CSV não encontrado: {results_csv}\")\n",
        "        return None\n",
        "\n",
        "# Visualizar resultados de ambas simulações\n",
        "df_30 = visualizar_resultados('simulacao_30_epocas')\n",
        "df_60 = visualizar_resultados('simulacao_60_epocas')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EWvSky11bGC",
        "outputId": "95587782-f417-4472-c413-2104231ceb05"
      },
      "id": "9EWvSky11bGC",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "📊 RESULTADOS - simulacao_30_epocas\n",
            "============================================================\n",
            "⚠️  Arquivo de resultados não encontrado: /content/drive/MyDrive/FarmTech_YOLO_Project/results/simulacao_30_epocas/results.png\n",
            "⚠️  CSV não encontrado: /content/drive/MyDrive/FarmTech_YOLO_Project/results/simulacao_30_epocas/results.csv\n",
            "\n",
            "============================================================\n",
            "📊 RESULTADOS - simulacao_60_epocas\n",
            "============================================================\n",
            "⚠️  Arquivo de resultados não encontrado: /content/drive/MyDrive/FarmTech_YOLO_Project/results/simulacao_60_epocas/results.png\n",
            "⚠️  CSV não encontrado: /content/drive/MyDrive/FarmTech_YOLO_Project/results/simulacao_60_epocas/results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # Import numpy\n",
        "import os # Import os for path joining\n",
        "\n",
        "def comparar_simulacoes(df_30, df_60):\n",
        "    \"\"\"\n",
        "    Compara os resultados das duas simulações\n",
        "    \"\"\"\n",
        "    if df_30 is None or df_60 is None:\n",
        "        print(\"⚠️  Dados não disponíveis para comparação\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🔍 COMPARAÇÃO DAS SIMULAÇÕES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Pegar últimas linhas (métricas finais)\n",
        "    final_30 = df_30.iloc[-1]\n",
        "    final_60 = df_60.iloc[-1]\n",
        "\n",
        "    # Criar DataFrame comparativo\n",
        "    comparacao = pd.DataFrame({\n",
        "        '30 Épocas': [\n",
        "            final_30.get('metrics/precision', 0),\n",
        "            final_30.get('metrics/recall', 0),\n",
        "            final_30.get('metrics/mAP_0.5', 0),\n",
        "            final_30.get('train/box_loss', 0),\n",
        "            final_30.get('val/box_loss', 0)\n",
        "        ],\n",
        "        '60 Épocas': [\n",
        "            final_60.get('metrics/precision', 0),\n",
        "            final_60.get('metrics/recall', 0),\n",
        "            final_60.get('metrics/mAP_0.5', 0),\n",
        "            final_60.get('train/box_loss', 0),\n",
        "            final_60.get('val/box_loss', 0)\n",
        "        ]\n",
        "    }, index=['Precisão', 'Recall', 'mAP@0.5', 'Loss Treino', 'Loss Validação'])\n",
        "\n",
        "    print(\"\\n📊 Tabela Comparativa:\")\n",
        "    print(comparacao.round(4))\n",
        "\n",
        "    # Calcular melhorias\n",
        "    melhoria_precisao = ((comparacao.loc['Precisão', '60 Épocas'] -\n",
        "                         comparacao.loc['Precisão', '30 Épocas']) /\n",
        "                        comparacao.loc['Precisão', '30 Épocas'] * 100)\n",
        "\n",
        "    melhoria_map = ((comparacao.loc['mAP@0.5', '60 Épocas'] -\n",
        "                    comparacao.loc['mAP@0.5', '30 Épocas']) /\n",
        "                   comparacao.loc['mAP@0.5', '30 Épocas'] * 100)\n",
        "\n",
        "    print(f\"\\n📈 Análise de Melhorias:\")\n",
        "    print(f\"   Melhoria na Precisão: {melhoria_precisao:+.2f}%\")\n",
        "    print(f\"   Melhoria no mAP@0.5: {melhoria_map:+.2f}%\")\n",
        "\n",
        "    # Criar gráfico comparativo\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Gráfico 1: Precisão e Recall\n",
        "    metrics = ['Precisão', 'Recall', 'mAP@0.5']\n",
        "    valores_30 = [comparacao.loc[m, '30 Épocas'] for m in metrics]\n",
        "    valores_60 = [comparacao.loc[m, '60 Épocas'] for m in metrics]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    axes[0].bar(x - width/2, valores_30, width, label='30 Épocas', color='#3498db')\n",
        "    axes[0].bar(x + width/2, valores_60, width, label='60 Épocas', color='#e74c3c')\n",
        "    axes[0].set_xlabel('Métricas')\n",
        "    axes[0].set_ylabel('Valor')\n",
        "    axes[0].set_title('Comparação de Métricas')\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels(metrics, rotation=45)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Gráfico 2: Loss\n",
        "    axes[1].plot(df_30['epoch'], df_30['train/box_loss'], 'b-', label='Train 30ep', alpha=0.7)\n",
        "    axes[1].plot(df_30['epoch'], df_30['val/box_loss'], 'b--', label='Val 30ep', alpha=0.7)\n",
        "    axes[1].plot(df_60['epoch'], df_60['train/box_loss'], 'r-', label='Train 60ep', alpha=0.7)\n",
        "    axes[1].plot(df_60['epoch'], df_60['val/box_loss'], 'r--', label='Val 60ep', alpha=0.7)\n",
        "    axes[1].set_xlabel('Épocas')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_title('Evolução do Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Gráfico 3: mAP evolution\n",
        "    axes[2].plot(df_30['epoch'], df_30['metrics/mAP_0.5'], 'b-', label='30 épocas', linewidth=2)\n",
        "    axes[2].plot(df_60['epoch'], df_60['metrics/mAP_0.5'], 'r-', label='60 épocas', linewidth=2)\n",
        "    axes[2].set_xlabel('Épocas')\n",
        "    axes[2].set_ylabel('mAP@0.5')\n",
        "    axes[2].set_title('Evolução do mAP@0.5')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(BASE_PATH, 'comparacao_simulacoes.png'), dpi=100, bbox_inches='tight') # Use os.path.join\n",
        "    plt.show()\n",
        "\n",
        "    return comparacao\n",
        "\n",
        "# Executar comparação\n",
        "if 'df_30' in locals() and 'df_60' in locals() and df_30 is not None and df_60 is not None:\n",
        "    comparacao_df = comparar_simulacoes(df_30, df_60)\n",
        "else:\n",
        "    print(\"ERRO: DataFrames 'df_30' e 'df_60' não foram definidos. Crie-os com os dados de suas simulações.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPXmLPuP3DC-",
        "outputId": "2f08d0bb-3e35-49ef-b84b-2f8f0aeda469"
      },
      "id": "nPXmLPuP3DC-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERRO: DataFrames 'df_30' e 'df_60' não foram definidos. Crie-os com os dados de suas simulações.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import os # Import os for path joining\n",
        "\n",
        "def testar_modelo(nome_experimento_treino, nome_experimento_teste, yaml_path):\n",
        "    \"\"\"\n",
        "    Executa o script test.py do YOLOv5 no melhor modelo de um experimento.\n",
        "    VERSÃO FINAL CORRIGIDA para o erro 'ValueError'.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🧪 INICIANDO TESTE - {nome_experimento_treino}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Use os.path.join para criar o caminho\n",
        "    weights_path = os.path.join(BASE_PATH, 'results', nome_experimento_treino, 'weights', 'best.pt')\n",
        "\n",
        "    if not os.path.exists(weights_path): # Use os.path.exists para verificar o caminho\n",
        "        print(f\"❌ ERRO: Pesos não encontrados em {weights_path}\")\n",
        "        return None, None\n",
        "\n",
        "    cmd = [\n",
        "        'python', 'val.py',\n",
        "        '--weights', str(weights_path),\n",
        "        '--data', str(yaml_path),\n",
        "        '--task', 'test',\n",
        "        '--img', '640',\n",
        "        '--device', 'cpu', # Change device to 'cpu' as per nvidia-smi output\n",
        "        '--project', str(os.path.join(BASE_PATH, 'results', 'test_results')), # Use os.path.join\n",
        "        '--name', nome_experimento_teste,\n",
        "        '--exist-ok'\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # --- A CORREÇÃO ESTÁ NESTA LINHA ---\n",
        "        # REMOVIDO: capture_output=True\n",
        "        # ADICIONADO: stdout=subprocess.PIPE\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            stdout=subprocess.PIPE,  # Captura a saída padrão\n",
        "            stderr=subprocess.STDOUT, # Redireciona o erro para a saída padrão\n",
        "            text=True,\n",
        "            check=True\n",
        "        )\n",
        "\n",
        "        print(\"✅ Teste concluído com sucesso!\")\n",
        "        print(\"\\n--- Resumo do Teste ---\")\n",
        "        print(result.stdout)\n",
        "\n",
        "        test_results_path = os.path.join(BASE_PATH, 'results', 'test_results', nome_experimento_teste) # Use os.path.join\n",
        "        return result.stdout, test_results_path\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"⚠️ Erro no teste:\")\n",
        "        print(e.stdout)\n",
        "        return None, None\n",
        "\n",
        "def parse_test_results(output_text):\n",
        "    \"\"\"\n",
        "    Extrai as métricas da saída de texto do script val.py.\n",
        "    \"\"\"\n",
        "    if not output_text:\n",
        "        return {}\n",
        "\n",
        "    metrics = {}\n",
        "    # Padrão para encontrar a linha 'all' com as métricas\n",
        "    match = re.search(r'all\\s+\\d+\\s+\\d+\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)', output_text)\n",
        "\n",
        "    if match:\n",
        "        metrics['metrics/precision'] = float(match.group(1))\n",
        "        metrics['metrics/recall'] = float(match.group(2))\n",
        "        metrics['metrics/mAP_0.5'] = float(match.group(3))\n",
        "        metrics['metrics/mAP_0.5:0.95'] = float(match.group(4))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# --- Executando os testes para ambos os modelos ---\n",
        "\n",
        "# Testar o modelo de 30 épocas\n",
        "output_30, test_path_30 = testar_modelo('simulacao_30_epocas', 'teste_modelo_30_epocas', yaml_path)\n",
        "test_metrics_30 = parse_test_results(output_30)\n",
        "\n",
        "# Testar o modelo de 60 épocas\n",
        "output_60, test_path_60 = testar_modelo('simulacao_60_epocas', 'teste_modelo_60_epocas', yaml_path)\n",
        "test_metrics_60 = parse_test_results(output_60)\n",
        "\n",
        "print(\"\\n\\n--- Métricas Extraídas do Teste ---\")\n",
        "print(\"\\nModelo 30 Épocas (Teste):\")\n",
        "print(test_metrics_30)\n",
        "\n",
        "print(\"\\nModelo 60 Épocas (Teste):\")\n",
        "print(test_metrics_60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivsjm4LY4G1h",
        "outputId": "5408659c-8b42-4421-ff92-9c8500d1b594"
      },
      "id": "ivsjm4LY4G1h",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "🧪 INICIANDO TESTE - simulacao_30_epocas\n",
            "============================================================\n",
            "❌ ERRO: Pesos não encontrados em /content/drive/MyDrive/FarmTech_YOLO_Project/results/simulacao_30_epocas/weights/best.pt\n",
            "\n",
            "============================================================\n",
            "🧪 INICIANDO TESTE - simulacao_60_epocas\n",
            "============================================================\n",
            "❌ ERRO: Pesos não encontrados em /content/drive/MyDrive/FarmTech_YOLO_Project/results/simulacao_60_epocas/weights/best.pt\n",
            "\n",
            "\n",
            "--- Métricas Extraídas do Teste ---\n",
            "\n",
            "Modelo 30 Épocas (Teste):\n",
            "{}\n",
            "\n",
            "Modelo 60 Épocas (Teste):\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def comparar_resultados_completos(df_val_30, df_val_60, test_metrics_30, test_metrics_60, test_path_30, test_path_60):\n",
        "    \"\"\"\n",
        "    Compara os resultados de validação e teste de ambas as simulações.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"🏆 COMPARAÇÃO FINAL: VALIDAÇÃO vs. TESTE\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    if df_val_30 is None or df_val_60 is None or not test_metrics_30 or not test_metrics_60:\n",
        "        print(\"⚠️ Faltam dados para a comparação completa. Verifique se todas as etapas anteriores foram executadas.\")\n",
        "        return\n",
        "\n",
        "    # Pegar as melhores métricas da validação (ao invés das últimas)\n",
        "    best_val_30 = df_val_30.loc[df_val_30['metrics/mAP_0.5'].idxmax()]\n",
        "    best_val_60 = df_val_60.loc[df_val_60['metrics/mAP_0.5'].idxmax()]\n",
        "\n",
        "    # --- Tabela Comparativa ---\n",
        "    data = {\n",
        "        ('Modelo 30 Épocas', 'Validação'): {\n",
        "            'mAP@0.5': best_val_30.get('metrics/mAP_0.5', 0),\n",
        "            'Precisão': best_val_30.get('metrics/precision', 0),\n",
        "            'Recall': best_val_30.get('metrics/recall', 0)\n",
        "        },\n",
        "        ('Modelo 30 Épocas', 'Teste'): {\n",
        "            'mAP@0.5': test_metrics_30.get('metrics/mAP_0.5', 0),\n",
        "            'Precisão': test_metrics_30.get('metrics/precision', 0),\n",
        "            'Recall': test_metrics_30.get('metrics/recall', 0)\n",
        "        },\n",
        "        ('Modelo 60 Épocas', 'Validação'): {\n",
        "            'mAP@0.5': best_val_60.get('metrics/mAP_0.5', 0),\n",
        "            'Precisão': best_val_60.get('metrics/precision', 0),\n",
        "            'Recall': best_val_60.get('metrics/recall', 0)\n",
        "        },\n",
        "        ('Modelo 60 Épocas', 'Teste'): {\n",
        "            'mAP@0.5': test_metrics_60.get('metrics/mAP_0.5', 0),\n",
        "            'Precisão': test_metrics_60.get('metrics/precision', 0),\n",
        "            'Recall': test_metrics_60.get('metrics/recall', 0)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    comp_df = pd.DataFrame(data).round(4)\n",
        "    print(\"\\n📊 Tabela Comparativa de Desempenho (Pico da Validação vs. Teste):\")\n",
        "    display(comp_df)\n",
        "\n",
        "    # --- Matrizes de Confusão do Teste ---\n",
        "    print(\"\\n🔲 Matriz de Confusão (Conjunto de Teste) - Modelo 30 Épocas:\")\n",
        "    confusion_matrix_30 = os.path.join(test_path_30, 'confusion_matrix.png')\n",
        "    if os.path.exists(confusion_matrix_30):\n",
        "        display(Image(filename=str(confusion_matrix_30)))\n",
        "    else:\n",
        "        print(f\"⚠️ Imagem não encontrada: {confusion_matrix_30}\")\n",
        "\n",
        "    print(\"\\n🔲 Matriz de Confusão (Conjunto de Teste) - Modelo 60 Épocas:\")\n",
        "    confusion_matrix_60 = os.path.join(test_path_60, 'confusion_matrix.png')\n",
        "    if os.path.exists(confusion_matrix_60):\n",
        "        display(Image(filename=str(confusion_matrix_60)))\n",
        "    else:\n",
        "        print(f\"⚠️ Imagem não encontrada: {confusion_matrix_60}\")\n",
        "\n",
        "    # --- Análise e Conclusão ---\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"✍️ ANÁLISE E CONCLUSÃO FINAL\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    gap_30 = comp_df[('Modelo 30 Épocas', 'Validação')]['mAP@0.5'] - comp_df[('Modelo 30 Épocas', 'Teste')]['mAP@0.5']\n",
        "    gap_60 = comp_df[('Modelo 60 Épocas', 'Validação')]['mAP@0.5'] - comp_df[('Modelo 60 Épocas', 'Teste')]['mAP@0.5']\n",
        "\n",
        "    print(f\"📉 'Gap de Generalização' (Validação - Teste) para mAP@0.5:\")\n",
        "    print(f\"   - Modelo 30 Épocas: {gap_30:.4f}\")\n",
        "    print(f\"   - Modelo 60 Épocas: {gap_60:.4f}\")\n",
        "    print(\"   (Um gap menor indica que o modelo generaliza melhor para novos dados)\")\n",
        "\n",
        "    map_teste_30 = comp_df[('Modelo 30 Épocas', 'Teste')]['mAP@0.5']\n",
        "    map_teste_60 = comp_df[('Modelo 60 Épocas', 'Teste')]['mAP@0.5']\n",
        "\n",
        "    print(\"\\n💡 RECOMENDAÇÃO:\")\n",
        "    if map_teste_60 > map_teste_30:\n",
        "        if gap_60 < gap_30 * 1.5: # Se o gap do modelo 60 não for muito maior\n",
        "             print(\"   ✅ O **Modelo de 60 Épocas** é o recomendado. Ele demonstrou o melhor desempenho no conjunto de teste, provando sua superioridade em dados não vistos e mantendo uma boa capacidade de generalização.\")\n",
        "        else:\n",
        "             print(\"   ⚠️ O **Modelo de 60 Épocas** teve o melhor desempenho no teste, mas seu 'gap de generalização' é consideravelmente maior. Isso pode ser um sinal de overfitting. Embora seja o melhor modelo, os resultados devem ser monitorados.\")\n",
        "    elif map_teste_30 > map_teste_60:\n",
        "        print(\"   ✅ O **Modelo de 30 Épocas** é o recomendado. Apesar de ter treinado por menos tempo, ele generalizou melhor para os dados de teste, mostrando-se mais robusto e eficiente.\")\n",
        "    else:\n",
        "        print(\"   ⚖️ Ambos os modelos tiveram desempenho idêntico no teste. O **Modelo de 30 Épocas** é recomendado por ser computacionalmente mais barato e igualmente eficaz.\")\n",
        "\n",
        "\n",
        "# --- Executar a comparação final ---\n",
        "if 'df_30' in locals() and 'df_60' in locals() and 'test_metrics_30' in locals() and 'test_path_30' in locals():\n",
        "    comparar_resultados_completos(df_30, df_60, test_metrics_30, test_metrics_60, test_path_30, test_path_60)\n",
        "else:\n",
        "    print(\"\\nERRO: Variáveis necessárias para a comparação não foram encontradas. Execute as células anteriores.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDw0NhA9bd5Q",
        "outputId": "880b80f7-cb0d-4d7b-b79d-592c44bab3a7"
      },
      "id": "QDw0NhA9bd5Q",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "🏆 COMPARAÇÃO FINAL: VALIDAÇÃO vs. TESTE\n",
            "================================================================================\n",
            "⚠️ Faltam dados para a comparação completa. Verifique se todas as etapas anteriores foram executadas.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}