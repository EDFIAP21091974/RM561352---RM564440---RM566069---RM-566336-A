{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EDFIAP21091974/RM561352---RM564440---RM566069---RM-566336-A/blob/main/Tarefa2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfZpDLRY2s0r",
        "outputId": "a2079c44-93e8-45b1-f567-e844b653274b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Drive montado e BASE_PATH definido como: /content/drive/MyDrive/FarmTech_YOLO_Project\n",
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 12362, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 12362 (delta 78), reused 48 (delta 48), pack-reused 12247 (from 5)\u001b[K\n",
            "Receiving objects: 100% (12362/12362), 10.84 MiB | 23.83 MiB/s, done.\n",
            "Resolving deltas: 100% (8348/8348), done.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.16.2)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 15))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.64 (from -r requirements.txt (line 19))\n",
            "  Downloading ultralytics-8.3.217-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 6)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.4.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 19)) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.64->-r requirements.txt (line 19))\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 28)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 28)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 6)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 16)) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.217-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.217 ultralytics-thop-2.0.17\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17611, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 17611 (delta 8), reused 2 (delta 2), pack-reused 17595 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17611/17611), 16.84 MiB | 24.35 MiB/s, done.\n",
            "Resolving deltas: 100% (11984/11984), done.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.64 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (8.3.217)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (2.0.17)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# C√©lula de configura√ß√£o para Google Colab\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Definir o caminho base NO SEU DRIVE\n",
        "BASE_PATH = Path('/content/drive/MyDrive/FarmTech_YOLO_Project/')\n",
        "\n",
        "# 3. Criar a pasta do projeto no Drive (se ainda n√£o existir)\n",
        "BASE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Drive montado e BASE_PATH definido como: {BASE_PATH}\")\n",
        "\n",
        "# Navegar para o diret√≥rio de trabalho do Colab para clonar os reposit√≥rios\n",
        "# Isso √© mais r√°pido do que clonar diretamente no Drive\n",
        "os.chdir('/content/')\n",
        "\n",
        "# Clone o reposit√≥rio do YOLOv3 (se ainda n√£o tiver clonado nesta sess√£o)\n",
        "if not Path('yolov3').exists():\n",
        "    !git clone https://github.com/ultralytics/yolov3\n",
        "    !cd yolov3 && pip install -r requirements.txt\n",
        "\n",
        "# Clone o reposit√≥rio do YOLOv5 (se ainda n√£o tiver clonado nesta sess√£o)\n",
        "if not Path('yolov5').exists():\n",
        "    !git clone https://github.com/ultralytics/yolov5\n",
        "    !cd yolov5 && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# C√âLULA 1: CONFIGURA√á√ÉO E IMPORTS (VERS√ÉO GOOGLE COLAB)\n",
        "# ===================================================================\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# --- Montar Drive e Definir Caminho Base (ESSENCIAL) ---\n",
        "drive.mount('/content/drive')\n",
        "BASE_PATH = Path('/content/drive/MyDrive/FarmTech_YOLO_Project/')\n",
        "BASE_PATH.mkdir(parents=True, exist_ok=True) # Garante que a pasta existe\n",
        "print(f\"üìÅ Pasta do projeto no Drive: {BASE_PATH}\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# C√âLULA 2: PREPARA√á√ÉO DO DATASET DE CLASSIFICA√á√ÉO (sem altera√ß√µes)\n",
        "# ===================================================================\n",
        "originais_path = BASE_PATH / 'imagens_originais'\n",
        "classificacao_path = BASE_PATH / 'dataset_classificacao'\n",
        "classes = ['cachorros', 'gatos']\n",
        "\n",
        "def organizar_dataset_classificacao(origem, destino, split_ratio=0.8):\n",
        "    if destino.exists():\n",
        "        print(f\"‚ö†Ô∏è  A pasta '{destino.name}' j√° existe. Nenhuma a√ß√£o foi tomada.\")\n",
        "        return\n",
        "    print(\" reorganizando dataset para classifica√ß√£o...\")\n",
        "    for split in ['train', 'val']:\n",
        "        for classe in classes:\n",
        "            (destino / split / classe).mkdir(parents=True, exist_ok=True)\n",
        "    for classe in classes:\n",
        "        imagens = list((origem / classe).glob('*'))\n",
        "        random.shuffle(imagens)\n",
        "        split_point = int(len(imagens) * split_ratio)\n",
        "        train_files, val_files = imagens[:split_point], imagens[split_point:]\n",
        "        for f in train_files:\n",
        "            shutil.copy(f, destino / 'train' / classe / f.name)\n",
        "        for f in val_files:\n",
        "            shutil.copy(f, destino / 'val' / classe / f.name)\n",
        "    print(f\"‚úÖ Dataset de classifica√ß√£o criado com sucesso em: {destino}\")\n",
        "\n",
        "organizar_dataset_classificacao(originais_path, classificacao_path)\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# C√âLULA 3: DEFINI√á√ÉO DO MODELO CNN (sem altera√ß√µes)\n",
        "# ===================================================================\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, 3, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, 3, 1), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 6 * 6, 512), # Ajustado para entrada 64x64 com padding 0\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# C√âLULA 4: TREINAMENTO DO MODELO (com pequeno ajuste)\n",
        "# ===================================================================\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((64, 64)), transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((64, 64)), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(classificacao_path / x, data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "# --- AJUSTE PARA COLAB ---\n",
        "# num_workers=2 √© mais est√°vel no Google Colab do que 4\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN(num_classes=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# (O resto do loop de treinamento continua exatamente igual...)\n",
        "\n",
        "# Loop de Treinamento\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs); _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward(); optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\\n')\n",
        "\n",
        "print('‚úÖ Treinamento da CNN conclu√≠do!')\n",
        "torch.save(model.state_dict(), BASE_PATH / 'models' / 'cnn_classificador_final.pth')\n",
        "print(\"Modelo salvo em 'models/cnn_classificador_final.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "9hR19UkQ4KDY",
        "outputId": "fa2b0da8-55ba-47e0-c946-391f242c8b24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìÅ Pasta do projeto no Drive: /content/drive/MyDrive/FarmTech_YOLO_Project\n",
            " reorganizando dataset para classifica√ß√£o...\n",
            "‚úÖ Dataset de classifica√ß√£o criado com sucesso em: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset_classificacao\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Found no valid file for the classes cachorros, gatos. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-462573133.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m }\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificacao_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# --- AJUSTE PARA COLAB ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes cachorros, gatos. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def organizar_dataset_completo(origem, destino, splits=(0.7, 0.15, 0.15)):\n",
        "    \"\"\"\n",
        "    Organiza o dataset em conjuntos de treino, valida√ß√£o e teste.\n",
        "    \"\"\"\n",
        "    if sum(splits) != 1.0:\n",
        "        print(\"Erro: A soma das divis√µes deve ser 1.0\")\n",
        "        return\n",
        "\n",
        "    if destino.exists():\n",
        "        print(f\"‚ö†Ô∏è  A pasta '{destino.name}' j√° existe. Apague-a primeiro para recriar.\")\n",
        "        return\n",
        "\n",
        "    print(\" Reorganizando dataset em treino, valida√ß√£o e teste...\")\n",
        "\n",
        "    extensoes_validas = ['.jpg', '.jpeg', '.png', '.jfif', '.webp']\n",
        "\n",
        "    # Criar a nova estrutura de pastas\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for classe in classes:\n",
        "            (destino / split / classe).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for classe in classes:\n",
        "        imagens = []\n",
        "        for ext in extensoes_validas:\n",
        "            imagens.extend(list((origem / classe).glob(f\"*{ext.lower()}\")))\n",
        "            imagens.extend(list((origem / classe).glob(f\"*{ext.upper()}\")))\n",
        "\n",
        "        imagens = list(set(imagens))\n",
        "        random.shuffle(imagens)\n",
        "\n",
        "        # Pontos de corte\n",
        "        ponto1 = int(len(imagens) * splits[0])\n",
        "        ponto2 = int(len(imagens) * (splits[0] + splits[1]))\n",
        "\n",
        "        # Dividir arquivos\n",
        "        train_files = imagens[:ponto1]\n",
        "        val_files = imagens[ponto1:ponto2]\n",
        "        test_files = imagens[ponto2:]\n",
        "\n",
        "        # Copiar arquivos\n",
        "        for f in train_files: shutil.copy(f, destino / 'train' / classe / f.name)\n",
        "        for f in val_files: shutil.copy(f, destino / 'val' / classe / f.name)\n",
        "        for f in test_files: shutil.copy(f, destino / 'test' / classe / f.name)\n",
        "\n",
        "    print(f\"‚úÖ Dataset completo criado com sucesso em: {destino}\")\n",
        "\n",
        "originais_path = BASE_PATH / 'imagens_originais'\n",
        "classificacao_path = BASE_PATH / 'dataset_classificacao'\n",
        "classes = ['cachorros', 'gatos']\n",
        "\n",
        "organizar_dataset_completo(originais_path, classificacao_path)"
      ],
      "metadata": {
        "id": "4Gt53fsKVKT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C√âLULA DE TESTE FINAL DO MODELO\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ... (c√≥digo para carregar dados e o modelo - sem altera√ß√µes) ...\n",
        "# 1. Carregar os dados de Teste\n",
        "test_dir = classificacao_path / 'test'\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_dataset = datasets.ImageFolder(test_dir, test_transforms)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# 2. Carregar o Modelo Treinado\n",
        "caminho_modelo_salvo = BASE_PATH / 'models' / 'cnn_classificador_final.pth'\n",
        "model = SimpleCNN(num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(caminho_modelo_salvo))\n",
        "model.eval()\n",
        "\n",
        "# 3. Fazer as Previs√µes\n",
        "todas_as_preds = []\n",
        "todas_as_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_dataloader, desc=\"Testando...\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        todas_as_preds.extend(preds.cpu().numpy())\n",
        "        todas_as_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# 4. Gerar e Exibir os Resultados\n",
        "print(\"\\n\" + \"=\"*50); print(\"üìä RELAT√ìRIO DE CLASSIFICA√á√ÉO NO CONJUNTO DE TESTE\"); print(\"=\"*50)\n",
        "nomes_classes = image_datasets['train'].classes\n",
        "report = classification_report(todas_as_labels, todas_as_preds, target_names=nomes_classes)\n",
        "print(report)\n",
        "\n",
        "# Salvar o relat√≥rio em um arquivo de texto ---\n",
        "report_path = BASE_PATH / 'results' / 'cnn_classification_report.txt'\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(report)\n",
        "print(f\"\\n‚úÖ Relat√≥rio de classifica√ß√£o salvo em: {report_path}\")\n",
        "# ----------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*50); print(\"üî≤ MATRIZ DE CONFUS√ÉO\"); print(\"=\"*50)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ConfusionMatrixDisplay.from_predictions(todas_as_labels, todas_as_preds, ax=ax, display_labels=nomes_classes, cmap='Blues')\n",
        "plt.title('Matriz de Confus√£o no Conjunto de Teste')\n",
        "\n",
        "# Salvar o gr√°fico da matriz de confus√£o ---\n",
        "figure_path = BASE_PATH / 'results' / 'cnn_confusion_matrix.png'\n",
        "plt.savefig(figure_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"‚úÖ Matriz de confus√£o salva em: {figure_path}\")\n",
        "# ---------------------------------------------------\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uddbXzWmWNF6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}