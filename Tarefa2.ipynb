{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EDFIAP21091974/RM561352---RM564440---RM566069---RM-566336-A/blob/main/Tarefa2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfZpDLRY2s0r",
        "outputId": "a2079c44-93e8-45b1-f567-e844b653274b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Drive montado e BASE_PATH definido como: /content/drive/MyDrive/FarmTech_YOLO_Project\n",
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 12362, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 12362 (delta 78), reused 48 (delta 48), pack-reused 12247 (from 5)\u001b[K\n",
            "Receiving objects: 100% (12362/12362), 10.84 MiB | 23.83 MiB/s, done.\n",
            "Resolving deltas: 100% (8348/8348), done.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.16.2)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 15))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.64 (from -r requirements.txt (line 19))\n",
            "  Downloading ultralytics-8.3.217-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 6)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 13)) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 16)) (3.4.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 19)) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.64->-r requirements.txt (line 19))\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 28)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 28)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 6)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 16)) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.217-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.217 ultralytics-thop-2.0.17\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17611, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 17611 (delta 8), reused 2 (delta 2), pack-reused 17595 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17611/17611), 16.84 MiB | 24.35 MiB/s, done.\n",
            "Resolving deltas: 100% (11984/11984), done.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.64 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (8.3.217)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (2.0.17)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Célula de configuração para Google Colab\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Definir o caminho base NO SEU DRIVE\n",
        "BASE_PATH = Path('/content/drive/MyDrive/FarmTech_YOLO_Project/')\n",
        "\n",
        "# 3. Criar a pasta do projeto no Drive (se ainda não existir)\n",
        "BASE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Drive montado e BASE_PATH definido como: {BASE_PATH}\")\n",
        "\n",
        "# Navegar para o diretório de trabalho do Colab para clonar os repositórios\n",
        "# Isso é mais rápido do que clonar diretamente no Drive\n",
        "os.chdir('/content/')\n",
        "\n",
        "# Clone o repositório do YOLOv3 (se ainda não tiver clonado nesta sessão)\n",
        "if not Path('yolov3').exists():\n",
        "    !git clone https://github.com/ultralytics/yolov3\n",
        "    !cd yolov3 && pip install -r requirements.txt\n",
        "\n",
        "# Clone o repositório do YOLOv5 (se ainda não tiver clonado nesta sessão)\n",
        "if not Path('yolov5').exists():\n",
        "    !git clone https://github.com/ultralytics/yolov5\n",
        "    !cd yolov5 && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# CÉLULA 1: CONFIGURAÇÃO E IMPORTS (VERSÃO GOOGLE COLAB)\n",
        "# ===================================================================\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# --- Montar Drive e Definir Caminho Base (ESSENCIAL) ---\n",
        "drive.mount('/content/drive')\n",
        "BASE_PATH = Path('/content/drive/MyDrive/FarmTech_YOLO_Project/')\n",
        "BASE_PATH.mkdir(parents=True, exist_ok=True) # Garante que a pasta existe\n",
        "print(f\"📁 Pasta do projeto no Drive: {BASE_PATH}\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CÉLULA 2: PREPARAÇÃO DO DATASET DE CLASSIFICAÇÃO (sem alterações)\n",
        "# ===================================================================\n",
        "originais_path = BASE_PATH / 'imagens_originais'\n",
        "classificacao_path = BASE_PATH / 'dataset_classificacao'\n",
        "classes = ['cachorros', 'gatos']\n",
        "\n",
        "def organizar_dataset_classificacao(origem, destino, split_ratio=0.8):\n",
        "    if destino.exists():\n",
        "        print(f\"⚠️  A pasta '{destino.name}' já existe. Nenhuma ação foi tomada.\")\n",
        "        return\n",
        "    print(\" reorganizando dataset para classificação...\")\n",
        "    for split in ['train', 'val']:\n",
        "        for classe in classes:\n",
        "            (destino / split / classe).mkdir(parents=True, exist_ok=True)\n",
        "    for classe in classes:\n",
        "        imagens = list((origem / classe).glob('*'))\n",
        "        random.shuffle(imagens)\n",
        "        split_point = int(len(imagens) * split_ratio)\n",
        "        train_files, val_files = imagens[:split_point], imagens[split_point:]\n",
        "        for f in train_files:\n",
        "            shutil.copy(f, destino / 'train' / classe / f.name)\n",
        "        for f in val_files:\n",
        "            shutil.copy(f, destino / 'val' / classe / f.name)\n",
        "    print(f\"✅ Dataset de classificação criado com sucesso em: {destino}\")\n",
        "\n",
        "organizar_dataset_classificacao(originais_path, classificacao_path)\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CÉLULA 3: DEFINIÇÃO DO MODELO CNN (sem alterações)\n",
        "# ===================================================================\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, 3, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, 3, 1), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 6 * 6, 512), # Ajustado para entrada 64x64 com padding 0\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CÉLULA 4: TREINAMENTO DO MODELO (com pequeno ajuste)\n",
        "# ===================================================================\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((64, 64)), transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((64, 64)), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(classificacao_path / x, data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "# --- AJUSTE PARA COLAB ---\n",
        "# num_workers=2 é mais estável no Google Colab do que 4\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN(num_classes=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# (O resto do loop de treinamento continua exatamente igual...)\n",
        "\n",
        "# Loop de Treinamento\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs); _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward(); optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\\n')\n",
        "\n",
        "print('✅ Treinamento da CNN concluído!')\n",
        "torch.save(model.state_dict(), BASE_PATH / 'models' / 'cnn_classificador_final.pth')\n",
        "print(\"Modelo salvo em 'models/cnn_classificador_final.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "9hR19UkQ4KDY",
        "outputId": "fa2b0da8-55ba-47e0-c946-391f242c8b24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "📁 Pasta do projeto no Drive: /content/drive/MyDrive/FarmTech_YOLO_Project\n",
            " reorganizando dataset para classificação...\n",
            "✅ Dataset de classificação criado com sucesso em: /content/drive/MyDrive/FarmTech_YOLO_Project/dataset_classificacao\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Found no valid file for the classes cachorros, gatos. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-462573133.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m }\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificacao_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# --- AJUSTE PARA COLAB ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         samples = self.make_dataset(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return make_dataset(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes cachorros, gatos. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def organizar_dataset_completo(origem, destino, splits=(0.7, 0.15, 0.15)):\n",
        "    \"\"\"\n",
        "    Organiza o dataset em conjuntos de treino, validação e teste.\n",
        "    \"\"\"\n",
        "    if sum(splits) != 1.0:\n",
        "        print(\"Erro: A soma das divisões deve ser 1.0\")\n",
        "        return\n",
        "\n",
        "    if destino.exists():\n",
        "        print(f\"⚠️  A pasta '{destino.name}' já existe. Apague-a primeiro para recriar.\")\n",
        "        return\n",
        "\n",
        "    print(\" Reorganizando dataset em treino, validação e teste...\")\n",
        "\n",
        "    extensoes_validas = ['.jpg', '.jpeg', '.png', '.jfif', '.webp']\n",
        "\n",
        "    # Criar a nova estrutura de pastas\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for classe in classes:\n",
        "            (destino / split / classe).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for classe in classes:\n",
        "        imagens = []\n",
        "        for ext in extensoes_validas:\n",
        "            imagens.extend(list((origem / classe).glob(f\"*{ext.lower()}\")))\n",
        "            imagens.extend(list((origem / classe).glob(f\"*{ext.upper()}\")))\n",
        "\n",
        "        imagens = list(set(imagens))\n",
        "        random.shuffle(imagens)\n",
        "\n",
        "        # Pontos de corte\n",
        "        ponto1 = int(len(imagens) * splits[0])\n",
        "        ponto2 = int(len(imagens) * (splits[0] + splits[1]))\n",
        "\n",
        "        # Dividir arquivos\n",
        "        train_files = imagens[:ponto1]\n",
        "        val_files = imagens[ponto1:ponto2]\n",
        "        test_files = imagens[ponto2:]\n",
        "\n",
        "        # Copiar arquivos\n",
        "        for f in train_files: shutil.copy(f, destino / 'train' / classe / f.name)\n",
        "        for f in val_files: shutil.copy(f, destino / 'val' / classe / f.name)\n",
        "        for f in test_files: shutil.copy(f, destino / 'test' / classe / f.name)\n",
        "\n",
        "    print(f\"✅ Dataset completo criado com sucesso em: {destino}\")\n",
        "\n",
        "originais_path = BASE_PATH / 'imagens_originais'\n",
        "classificacao_path = BASE_PATH / 'dataset_classificacao'\n",
        "classes = ['cachorros', 'gatos']\n",
        "\n",
        "organizar_dataset_completo(originais_path, classificacao_path)"
      ],
      "metadata": {
        "id": "4Gt53fsKVKT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA DE TESTE FINAL DO MODELO\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ... (código para carregar dados e o modelo - sem alterações) ...\n",
        "# 1. Carregar os dados de Teste\n",
        "test_dir = classificacao_path / 'test'\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_dataset = datasets.ImageFolder(test_dir, test_transforms)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# 2. Carregar o Modelo Treinado\n",
        "caminho_modelo_salvo = BASE_PATH / 'models' / 'cnn_classificador_final.pth'\n",
        "model = SimpleCNN(num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(caminho_modelo_salvo))\n",
        "model.eval()\n",
        "\n",
        "# 3. Fazer as Previsões\n",
        "todas_as_preds = []\n",
        "todas_as_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_dataloader, desc=\"Testando...\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        todas_as_preds.extend(preds.cpu().numpy())\n",
        "        todas_as_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# 4. Gerar e Exibir os Resultados\n",
        "print(\"\\n\" + \"=\"*50); print(\"📊 RELATÓRIO DE CLASSIFICAÇÃO NO CONJUNTO DE TESTE\"); print(\"=\"*50)\n",
        "nomes_classes = image_datasets['train'].classes\n",
        "report = classification_report(todas_as_labels, todas_as_preds, target_names=nomes_classes)\n",
        "print(report)\n",
        "\n",
        "# Salvar o relatório em um arquivo de texto ---\n",
        "report_path = BASE_PATH / 'results' / 'cnn_classification_report.txt'\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(report)\n",
        "print(f\"\\n✅ Relatório de classificação salvo em: {report_path}\")\n",
        "# ----------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*50); print(\"🔲 MATRIZ DE CONFUSÃO\"); print(\"=\"*50)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ConfusionMatrixDisplay.from_predictions(todas_as_labels, todas_as_preds, ax=ax, display_labels=nomes_classes, cmap='Blues')\n",
        "plt.title('Matriz de Confusão no Conjunto de Teste')\n",
        "\n",
        "# Salvar o gráfico da matriz de confusão ---\n",
        "figure_path = BASE_PATH / 'results' / 'cnn_confusion_matrix.png'\n",
        "plt.savefig(figure_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"✅ Matriz de confusão salva em: {figure_path}\")\n",
        "# ---------------------------------------------------\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uddbXzWmWNF6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}